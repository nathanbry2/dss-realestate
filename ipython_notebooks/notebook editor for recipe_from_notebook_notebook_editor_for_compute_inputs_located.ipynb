{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-real_estate",
      "display_name": "Python (env real_estate)",
      "language": "python"
    },
    "associatedRecipe": "recipe_from_notebook_notebook_editor_for_compute_inputs_located",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "admin"
      },
      "lastModifiedOn": 1654291513832
    },
    "creator": "admin",
    "createdOn": 1654291513832,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.7.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 17,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\nfrom geoloc_functions import find_location,distance_to_centre, direction_from_centre\nfrom openlocationcode import openlocationcode as olc\nfrom pluscode_functions import convert_pluscode\nfrom iris_functions import create_iris_polygon_dict, find_iris"
      ],
      "outputs": []
    },
    {
      "execution_count": 18,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read recipe inputs\nnew_inputs \u003d dataiku.Dataset(\"new_inputs_editable\")\nnew_inputs_df \u003d new_inputs.get_dataframe()\niris_75 \u003d dataiku.Dataset(\"iris_75\")\niris_75_df \u003d iris_75.get_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "/Users/nathanbry/Dataiku/dss-design/code-envs/python/real_estate/lib/python3.7/site-packages/pandas/core/indexes/base.py:395: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  elif issubclass(data.dtype.type, np.bool) or is_bool_dtype(data):\n",
          "name": "stderr"
        }
      ]
    },
    {
      "execution_count": 29,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_inputs_df[\u0027adresse_full\u0027] \u003d new_inputs_df[\u0027adresse\u0027]+\u0027, \u0027+new_inputs_df[\u0027code_postal\u0027].astype(str)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "/Users/nathanbry/Dataiku/dss-design/code-envs/python/real_estate/lib/python3.7/site-packages/pandas/core/indexes/base.py:395: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  elif issubclass(data.dtype.type, np.bool) or is_bool_dtype(data):\n",
          "name": "stderr"
        }
      ]
    },
    {
      "execution_count": 31,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_inputs_df[\u0027latitude\u0027] \u003d find_location(new_inputs_df[\u0027adresse_full\u0027])[0]\nnew_inputs_df[\u0027longitude\u0027] \u003d find_location(new_inputs_df[\u0027adresse_full\u0027])[1]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "/Users/nathanbry/Dataiku/dss-design/code-envs/python/real_estate/lib/python3.7/site-packages/pandas/core/indexes/base.py:395: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  elif issubclass(data.dtype.type, np.bool) or is_bool_dtype(data):\n",
          "name": "stderr"
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_inputs_df"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_inputs_df[\u0027distance_to_centre\u0027]\u003d distance_to_centre(new_inputs_df[\u0027latitude\u0027],new_inputs_df[\u0027longitude\u0027])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_inputs_df[\u0027direction_from_centre\u0027] \u003d np.vectorize(direction_from_centre)(new_inputs_df[\u0027longitude\u0027],new_inputs_df[\u0027latitude\u0027])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_inputs_df"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_inputs_df[\u0027pluscode_16_first\u0027] \u003d np.vectorize(olc.encode)(new_inputs_df[\u0027latitude\u0027],new_inputs_df[\u0027longitude\u0027],17)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_inputs_df[\u0027pluscode_10\u0027] \u003d [code[:11] for code in new_inputs_df[\u0027pluscode_16_first\u0027].to_list()]"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_inputs_df[\u0027v_coordinate\u0027],new_inputs_df[\u0027h_coordinate\u0027],new_inputs_df[\u0027reduced_v_coordinate\u0027],new_inputs_df[\u0027reduced_h_coordinate\u0027],new_inputs_df[\u0027reduced_coordinates_couple\u0027] \u003d convert_pluscode(new_inputs_df[\u0027pluscode_10\u0027])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "iris_coords_codes \u003d create_iris_polygon_dict(iris_75_df[\u0027CODE_IRIS\u0027],iris_75_df[\u0027Geo Shape\u0027])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_inputs_df[\u0027iris_code\u0027] \u003d find_iris(new_inputs_df[\u0027latitude\u0027],new_inputs_df[\u0027longitude\u0027],iris_coords_codes)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def correct_date(date_column):\n\n    dates_list \u003d date_column.to_list()\n    new_dates_list \u003d []\n\n    for date in dates_list:\n        if date \u003e 2021:\n            new_date \u003d 2021\n        elif date \u003c 2014:\n            new_date \u003d 2014\n        else:\n            new_date \u003d date\n\n        new_dates_list.append(new_date)\n\n    return new_dates_list"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_inputs_df[\u0027date_mutation_year\u0027] \u003d correct_date(new_inputs_df[\u0027date_mutation_year\u0027])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute recipe outputs from inputs\n# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n\ninputs_located_df \u003d new_inputs_df # For this sample code, simply copy input to output\n\n\n# Write recipe outputs\ninputs_located \u003d dataiku.Dataset(\"inputs_located\")\ninputs_located.write_with_schema(inputs_located_df)"
      ],
      "outputs": []
    }
  ]
}